{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O nelinearnoj regresiji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kvadratna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U prethodna dva potpoglavlja smo uvidjeli dvije pogodnosti linearne regresije:\n",
    "    - Brza i jednostavna implementacija\n",
    "    - Tentativno prihvatljiva tačnost\n",
    "Stoga nam je ovaj algoritam koristan kada nam je potrebna neka brza i donekle kvalitetna analiza podataka. No, za neku ozbiljniju analizu podataka ili za neki precizniji model predikcije, linearna regresija je praktički neupotrebljiva. Npr. analizirajmo linearnu regresiju koju smo izračunali u prvom poglavlju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_line_height(x: float, k: float, n: float) -> float:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Hight of line y = k*x + n for given k, x and n parameters.\n",
    "    \"\"\"\n",
    "    return k * x + n\n",
    "\n",
    "def calculate_linear_regression_mse(\n",
    "    training_set: np.ndarray, m_0: float, m_1: float) -> float:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Mean squared error produced on top of provided training set,\n",
    "        using linear regression y = m_1*x + m_0\n",
    "    \"\"\"\n",
    "    inputs: np.ndarray = training_set.T[0]\n",
    "    outputs: np.ndarray = training_set.T[1]\n",
    "    linear_regression_predict: Callable[[float], float] = partial(\n",
    "        calculate_line_height, k=m_1, n=m_0)\n",
    "    \n",
    "    predictions: np.ndarray = linear_regression_predict(inputs)\n",
    "    squared_errors = (predictions - outputs) ** 2\n",
    "    \n",
    "    return np.mean(squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 10080774.695512515\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "name": "Training point",
         "type": "scatter",
         "uid": "beef55ac-802a-493c-b343-57547b7d60ad",
         "x": [
          10000,
          400000,
          5000,
          0,
          1000,
          100000,
          50000,
          50,
          20000,
          200000
         ],
         "y": [
          31000,
          19000,
          32000,
          40000,
          33000,
          26000,
          29000,
          35000,
          30000,
          20000
         ]
        },
        {
         "line": {
          "color": "green",
          "width": 3
         },
         "mode": "lines",
         "name": "Regression line",
         "type": "scatter",
         "uid": "fcde9247-4297-4a9c-a8fa-3cc9b4d32286",
         "x": [
          10000,
          400000,
          5000,
          0,
          1000,
          100000,
          50000,
          50,
          20000,
          200000
         ],
         "y": [
          32418.47367118483,
          15827.777194804326,
          32631.174908061505,
          32843.87614493818,
          32801.33589756284,
          28589.851407404716,
          30716.863776171445,
          32841.74913256941,
          31993.071197431487,
          24335.826669871254
         ]
        }
       ],
       "layout": {
        "hovermode": "closest",
        "showlegend": false,
        "xaxis": {
         "showticklabels": true,
         "ticks": "",
         "zeroline": false
        },
        "yaxis": {
         "showticklabels": true,
         "ticks": "",
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div id=\"2a586738-4695-4793-bc18-b44da306506c\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"2a586738-4695-4793-bc18-b44da306506c\")) {\n",
       "    Plotly.newPlot(\"2a586738-4695-4793-bc18-b44da306506c\", [{\"marker\": {\"color\": \"black\"}, \"mode\": \"markers\", \"name\": \"Training point\", \"x\": [10000, 400000, 5000, 0, 1000, 100000, 50000, 50, 20000, 200000], \"y\": [31000, 19000, 32000, 40000, 33000, 26000, 29000, 35000, 30000, 20000], \"type\": \"scatter\", \"uid\": \"beef55ac-802a-493c-b343-57547b7d60ad\"}, {\"line\": {\"color\": \"green\", \"width\": 3}, \"mode\": \"lines\", \"name\": \"Regression line\", \"x\": [10000, 400000, 5000, 0, 1000, 100000, 50000, 50, 20000, 200000], \"y\": [32418.47367118483, 15827.777194804326, 32631.174908061505, 32843.87614493818, 32801.33589756284, 28589.851407404716, 30716.863776171445, 32841.74913256941, 31993.071197431487, 24335.826669871254], \"type\": \"scatter\", \"uid\": \"fcde9247-4297-4a9c-a8fa-3cc9b4d32286\"}], {\"hovermode\": \"closest\", \"showlegend\": false, \"xaxis\": {\"showticklabels\": true, \"ticks\": \"\", \"zeroline\": false}, \"yaxis\": {\"showticklabels\": true, \"ticks\": \"\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"2a586738-4695-4793-bc18-b44da306506c\")) {window._Plotly.Plots.resize(document.getElementById(\"2a586738-4695-4793-bc18-b44da306506c\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"2a586738-4695-4793-bc18-b44da306506c\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"2a586738-4695-4793-bc18-b44da306506c\")) {\n",
       "    Plotly.newPlot(\"2a586738-4695-4793-bc18-b44da306506c\", [{\"marker\": {\"color\": \"black\"}, \"mode\": \"markers\", \"name\": \"Training point\", \"x\": [10000, 400000, 5000, 0, 1000, 100000, 50000, 50, 20000, 200000], \"y\": [31000, 19000, 32000, 40000, 33000, 26000, 29000, 35000, 30000, 20000], \"type\": \"scatter\", \"uid\": \"beef55ac-802a-493c-b343-57547b7d60ad\"}, {\"line\": {\"color\": \"green\", \"width\": 3}, \"mode\": \"lines\", \"name\": \"Regression line\", \"x\": [10000, 400000, 5000, 0, 1000, 100000, 50000, 50, 20000, 200000], \"y\": [32418.47367118483, 15827.777194804326, 32631.174908061505, 32843.87614493818, 32801.33589756284, 28589.851407404716, 30716.863776171445, 32841.74913256941, 31993.071197431487, 24335.826669871254], \"type\": \"scatter\", \"uid\": \"fcde9247-4297-4a9c-a8fa-3cc9b4d32286\"}], {\"hovermode\": \"closest\", \"showlegend\": false, \"xaxis\": {\"showticklabels\": true, \"ticks\": \"\", \"zeroline\": false}, \"yaxis\": {\"showticklabels\": true, \"ticks\": \"\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"2a586738-4695-4793-bc18-b44da306506c\")) {window._Plotly.Plots.resize(document.getElementById(\"2a586738-4695-4793-bc18-b44da306506c\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import plotly.offline as ply\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "# Instantiate dataset\n",
    "car_mileage_vs_value_data_set: List[List[int]] = [\n",
    "    (10000, 31000), (400000, 19000), (5000, 32000), (0, 40000),\n",
    "    (1000, 33000), (100000, 26000), (50000, 29000), (50, 35000),\n",
    "    (20000, 30000), (200000, 20000)]\n",
    "car_mileage_vs_value_data_set: np.ndarray = np.array(car_mileage_vs_value_data_set)\n",
    "car_mileages: np.ndarray = car_mileage_vs_value_data_set.T[0]\n",
    "car_values: np.ndarray = car_mileage_vs_value_data_set.T[1]\n",
    "\n",
    "# Instantiate plot.ly objects\n",
    "ply.init_notebook_mode(connected=True)\n",
    "\n",
    "plot_data = go.Scatter(x=car_mileages, \n",
    "                       y=car_values, \n",
    "                       mode='markers',\n",
    "                       marker=dict(color='black'),\n",
    "                       name='Training point')\n",
    "\n",
    "layout = go.Layout(xaxis=dict(ticks='', showticklabels=True,\n",
    "                              zeroline=False),\n",
    "                   yaxis=dict(ticks='', showticklabels=True,\n",
    "                              zeroline=False),\n",
    "                   showlegend=False, hovermode='closest')\n",
    "\n",
    "# Calculate linear regression\n",
    "assert len(car_mileages) == len(car_values), 'Invalid train/labels size'\n",
    "training_set_size: int = len(car_values)\n",
    "\n",
    "\n",
    "m_0_ = np.sum(car_mileages ** 2)\n",
    "m_1_ = np.dot(car_mileages, car_values)\n",
    "    \n",
    "x_ = np.mean(car_mileages)\n",
    "y_ = np.mean(car_values)\n",
    "    \n",
    "x__ = m_0_ / training_set_size / x_\n",
    "y__ = m_1_ / training_set_size / x_\n",
    "\n",
    "m_1: float = (y__ - y_) / (x__ - x_)\n",
    "m_0: float = y_ - m_1 * x_\n",
    "linear_regression_mse: float = calculate_linear_regression_mse(training_set=car_mileage_vs_value_data_set, m_0=m_0, m_1=m_1)\n",
    "print(f'MSE: {linear_regression_mse}')\n",
    "\n",
    "# Construct regression line\n",
    "calculus_linear_regression_line = go.Scatter(x=car_mileages, \n",
    "                                             y=car_mileages * m_1 + m_0,\n",
    "                                             mode='lines',\n",
    "                                             line=dict(color='green', width=3),\n",
    "                                             name='Regression line')\n",
    "\n",
    "# Plot both data and regression line\n",
    "figure = go.Figure(data=[plot_data,\n",
    "                         calculus_linear_regression_line],\n",
    "                   layout=layout)\n",
    "\n",
    "ply.iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobiveni MSE je za neke primjene praktički neprihvatljiv. Srednja greška cijene auta od $\\sqrt{MSE}=\\sqrt{10080774}\\$=3175\\$$ je većini kupaca prevelika."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Npr. u našem trening skupu stoji da auto koje je prešlo 200.000km košta 20.000\\\\$, dok naša linearna regresija procjenjuje isto auto na 24.335\\\\$ (pokrenite kod iznad za iscrtavanje plota i pređite kursorom miša preko tačke koordinata $(200k, 20k)$, a zatim preko prave regresije tačno iznad nje). U nekim primjenama, ovolika razlika između stvarne i procijenjene vrijednosti ili generalnije kazano, ovolika **greška** našeg **modela predikcije** je neprihvatljiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Srećom, postoje načini da se greška našeg modela smanji, ali ih moramo tražiti u promjeni samog modela. Jedna takva ideja leži u odbacivanju linearnosti iz modela regresije. Naime, postavlja se pitanje: Šta će se desiti ukoliko našu pravu linearne regresije, zamijenimo nekom krivom? Da li će ukupna greška modela biti manja? To jeste, u našem slučaju, da li će $MSE$ biti manji? Pogledajmo zajedno!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prije svega, koju krivu da koristimo? Prijestimo se naše linearne regresije u analitičkom zapisu: $$p: y = m_1\\cdot x + m_0$$ Dakle, postavlja se pitanje, kojom krivom da zamijenimo našu pravu $p$. Hajde da probamo sa nekom jednostavnom. Recimo, kvadratnom: $$p_2: y = m_2\\cdot x^2 + m_1\\cdot x + m_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tada se naš MSE transformira u $$MSE(m_0, m_1, m_2) = \\frac{1}{|\\chi|}\\cdot\\sum_{(x, y) \\in \\chi}{(m_2\\cdot x^2 + m_1\\cdot x + m_0 - y)^2}$$ gdje je $\\chi$ naš trening skup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dakle potrebno je pronaći parametre $m_0$, $m_1$ i $m_2$ takve da je navedeni $MSE$ što manji. Drugim riječima, potrebno je pronaći minimum funkcije više parametara $MSE(m_0, m_1, m_2)$. Srećom po nas, navedena funkcija je diferencijabilna, pa se možemo poslužiti alatima kalkulusa više promjenjivih da nađemo njen minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, ta sreća ne traje dugo, jer možemo ubrzo uvidjeti da je izračun datog minimuma, posebice rješavanje sistema parcijalnih izvoda, jedna groteska. *Unatoč tome, entuzijastičan student je u mnogome ohrabren da proba sprovesti taj račun, ako ništa, razonode radi.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilo kako bilo, sada se nećemo zamarati samim načinom pronalaska optimalnih parametara $m_0$, $m_1$ i $m_2$, nego ćemo iskoristiti neko postojeće (implementirano) rješenje. Jedno takvo rješenje je metoda `polyfit` biblioteke `numpy`. *Vrijedi pomenuti i to da je nelinearna regresija poznata i po imenu **polinomska regresija**. Otud i naziv metode `polyfit`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda `polyfit` prima tri obavezna parametra:\n",
    "- x: Lista svih x-koordinata trening skupa $\\chi$\n",
    "- y: Lista svih y-koordinata trening skupa $\\chi$\n",
    "- deg: Stepen $n$ polinoma $P[x] = m_n\\cdot x^n + m_{n-1}\\cdot x^{n-1} + \\dots + m_2\\cdot x^2 + m_1\\cdot x + m_0$ za koji želimo da pronađemo koeficijente $m_i\\in \\mathbb{R}$, $i=\\overline{0,n}$ takve da je $MSE(m_0, m_1, m_2, \\dots, m_n) = \\frac{1}{|\\chi|}\\cdot\\sum_{(x, y) \\in \\chi}{(m_n\\cdot x^n + m_{n-1}\\cdot x^{n-1} + \\dots + m_2\\cdot x^2 + m_1\\cdot x + m_0 - y)^2}$ što je moguće manji.\n",
    "\n",
    "I vraća upravo niz koeficijenata $m_i\\in \\mathbb{R}$, $i=\\overline{n,0}$ za koje je navedeni $MSE(m_0, m_1, m_2, \\dots, m_n)$ najmanji mogući."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pogledajmo demonstraciju na našem konkretnom trening skupu. Primijetimo da stavljajući da je `deg=2`, metodom polyfit nalazimo upravo koeficijente $m_0$, $m_1$ i $m_2$ naše kvadratne krive $p_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_2=1.737533245436812e-07, m_1=-0.10732409009949634, m_0=34234.81248740836\n"
     ]
    }
   ],
   "source": [
    "m_2, m_1, m_0 = np.polyfit(\n",
    "    x=car_mileages,\n",
    "    y=car_values,\n",
    "    deg=2)\n",
    "\n",
    "print(f'm_2={m_2}, m_1={m_1}, m_0={m_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementirajmo pomoćnu metodu `calculate_polynomial_mse(training_set, *coefficients)` koja za proslijeđen trening skup $\\chi=\\{(x_i, y_i) | i=\\overline{1,k}, k\\in\\mathbb{N}\\}$ i koeficijente $m_i\\in \\mathbb{R}$, $i=\\overline{n,0}$ računa $MSE(m_0, m_1, m_2, \\dots, m_n) = \\frac{1}{|\\chi|}\\cdot\\sum_{(x, y) \\in \\chi}{(m_n\\cdot x^n + m_{n-1}\\cdot x^{n-1} + \\dots + m_2\\cdot x^2 + m_1\\cdot x + m_0 - y)^2}$.\n",
    "Također, koristimo metodu `poly1d` biblioteke `numpy` kao olakšicu za izračunavanje vrijednosti polinoma $P[x]$. Ona prima jedan obavezan parametar, a to je niz koeficijenata $[m_0, m_1, \\dots, m_n]$ i vraća objekat koji je ekvivalent polinomu $P[x] = m_n\\cdot x^n + m_{n-1}\\cdot x^{n-1} + \\dots + m_2\\cdot x^2 + m_1\\cdot x + m_0$. Taj objekat nam pojednostavljuje izračunavanje datog polinoma $P[x]$ za dato $x$ i koeficijente $m_i\\in \\mathbb{R}$, $i=\\overline{0,n}$. Pogledajmo na koji način to radimo tačno u nastavku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def calculate_polynomial_mse(training_set: List[Tuple[float, float]], *coefficients: float) -> float:\n",
    "    polynomial = np.poly1d(coefficients)\n",
    "    \n",
    "    return sum([(polynomial(x) - y)**2 for x, y in training_set]) / len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izračunajmo $MSE(m_0,m_1,m_2)$ za prethodno pronađene koeficijente naše krive $p_2$ i uporedimo ga sa $MSE$-om dobivenim linearnom regresijom $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic regression MSE: 4816444.122719141\n",
      "Linear regression MSE: 10080774.695512515\n"
     ]
    }
   ],
   "source": [
    "quadratic_regression_mse: float = calculate_polynomial_mse(car_mileage_vs_value_data_set, m_2, m_1, m_0)\n",
    "print(f'Quadratic regression MSE: {quadratic_regression_mse}')\n",
    "print(f'Linear regression MSE: {linear_regression_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Značajna razlika! Prosječno odstupanje predviđene vrijednosti od stvarne, koristeći kvadratnu krivu, je $\\sqrt{MSE}=\\sqrt{4816444}\\$=2194\\$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iscrtajmo pronađenu krivu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "name": "Training point",
         "type": "scatter",
         "uid": "175198de-73de-45f3-8b61-26b1eddf4b27",
         "x": [
          10000,
          400000,
          5000,
          0,
          1000,
          100000,
          50000,
          50,
          20000,
          200000
         ],
         "y": [
          31000,
          19000,
          32000,
          40000,
          33000,
          26000,
          29000,
          35000,
          30000,
          20000
         ]
        },
        {
         "line": {
          "color": "green",
          "width": 3
         },
         "mode": "lines",
         "name": "Regression line",
         "type": "scatter",
         "uid": "9fba6c24-6a5c-4bbe-b72f-c84cf5d449e5",
         "x": [
          10000,
          400000,
          5000,
          0,
          1000,
          100000,
          50000,
          50,
          20000,
          200000
         ],
         "y": [
          32418.47367118483,
          15827.777194804326,
          32631.174908061505,
          32843.87614493818,
          32801.33589756284,
          28589.851407404716,
          30716.863776171445,
          32841.74913256941,
          31993.071197431487,
          24335.826669871254
         ]
        },
        {
         "line": {
          "color": "blue",
          "width": 3
         },
         "mode": "lines",
         "name": "Regression curve",
         "type": "scatter",
         "uid": "c8bf03cc-0a4a-497d-9d77-f9029c201fa2",
         "x": [
          0,
          8163.265306122449,
          16326.530612244898,
          24489.79591836735,
          32653.061224489797,
          40816.32653061225,
          48979.5918367347,
          57142.857142857145,
          65306.12244897959,
          73469.38775510204,
          81632.6530612245,
          89795.91836734694,
          97959.1836734694,
          106122.44897959183,
          114285.71428571429,
          122448.97959183673,
          130612.24489795919,
          138775.51020408163,
          146938.77551020408,
          155102.04081632654,
          163265.306122449,
          171428.57142857142,
          179591.83673469388,
          187755.10204081633,
          195918.3673469388,
          204081.63265306124,
          212244.89795918367,
          220408.16326530612,
          228571.42857142858,
          236734.69387755104,
          244897.95918367346,
          253061.22448979592,
          261224.48979591837,
          269387.7551020408,
          277551.02040816325,
          285714.28571428574,
          293877.55102040817,
          302040.8163265306,
          310204.0816326531,
          318367.3469387755,
          326530.612244898,
          334693.8775510204,
          342857.14285714284,
          351020.4081632653,
          359183.67346938775,
          367346.93877551024,
          375510.20408163266,
          383673.4693877551,
          391836.7346938776,
          400000
         ],
         "y": [
          34234.81248740836,
          33370.276196686515,
          32528.89736696175,
          31710.675998234063,
          30915.612090503448,
          30143.70564376991,
          29394.956658033447,
          28669.365133294057,
          27966.931069551745,
          27287.654466806507,
          26631.535325058343,
          25998.57364430726,
          25388.769424553248,
          24802.122665796313,
          24238.633368036448,
          23698.301531273664,
          23181.127155507955,
          22687.11024073932,
          22216.25078696776,
          21768.548794193277,
          21344.004262415867,
          20942.617191635538,
          20564.38758185228,
          20209.315433066095,
          19877.400745276987,
          19568.643518484954,
          19283.043752690002,
          19020.60144789212,
          18781.316604091313,
          18565.189221287583,
          18372.21929948093,
          18202.406838671348,
          18055.751838858847,
          17932.254300043416,
          17831.914222225067,
          17754.731605403787,
          17700.706449579586,
          17669.838754752458,
          17662.128520922408,
          17677.575748089428,
          17716.18043625353,
          17777.942585414705,
          17862.862195572954,
          17970.93926672828,
          18102.173798880678,
          18256.565792030153,
          18434.115246176705,
          18634.822161320335,
          18858.686537461035,
          19105.708374598813
         ]
        }
       ],
       "layout": {
        "hovermode": "closest",
        "showlegend": false,
        "xaxis": {
         "showticklabels": true,
         "ticks": "",
         "zeroline": false
        },
        "yaxis": {
         "showticklabels": true,
         "ticks": "",
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div id=\"28155046-3ea1-4022-8cdd-767475bad2b2\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"28155046-3ea1-4022-8cdd-767475bad2b2\")) {\n",
       "    Plotly.newPlot(\"28155046-3ea1-4022-8cdd-767475bad2b2\", [{\"marker\": {\"color\": \"black\"}, \"mode\": \"markers\", \"name\": \"Training point\", \"x\": [10000, 400000, 5000, 0, 1000, 100000, 50000, 50, 20000, 200000], \"y\": [31000, 19000, 32000, 40000, 33000, 26000, 29000, 35000, 30000, 20000], \"type\": \"scatter\", \"uid\": \"175198de-73de-45f3-8b61-26b1eddf4b27\"}, {\"line\": {\"color\": \"green\", \"width\": 3}, \"mode\": \"lines\", \"name\": \"Regression line\", \"x\": [10000, 400000, 5000, 0, 1000, 100000, 50000, 50, 20000, 200000], \"y\": [32418.47367118483, 15827.777194804326, 32631.174908061505, 32843.87614493818, 32801.33589756284, 28589.851407404716, 30716.863776171445, 32841.74913256941, 31993.071197431487, 24335.826669871254], \"type\": \"scatter\", \"uid\": \"9fba6c24-6a5c-4bbe-b72f-c84cf5d449e5\"}, {\"line\": {\"color\": \"blue\", \"width\": 3}, \"mode\": \"lines\", \"name\": \"Regression curve\", \"x\": [0.0, 8163.265306122449, 16326.530612244898, 24489.79591836735, 32653.061224489797, 40816.32653061225, 48979.5918367347, 57142.857142857145, 65306.12244897959, 73469.38775510204, 81632.6530612245, 89795.91836734694, 97959.1836734694, 106122.44897959183, 114285.71428571429, 122448.97959183673, 130612.24489795919, 138775.51020408163, 146938.77551020408, 155102.04081632654, 163265.306122449, 171428.57142857142, 179591.83673469388, 187755.10204081633, 195918.3673469388, 204081.63265306124, 212244.89795918367, 220408.16326530612, 228571.42857142858, 236734.69387755104, 244897.95918367346, 253061.22448979592, 261224.48979591837, 269387.7551020408, 277551.02040816325, 285714.28571428574, 293877.55102040817, 302040.8163265306, 310204.0816326531, 318367.3469387755, 326530.612244898, 334693.8775510204, 342857.14285714284, 351020.4081632653, 359183.67346938775, 367346.93877551024, 375510.20408163266, 383673.4693877551, 391836.7346938776, 400000.0], \"y\": [34234.81248740836, 33370.276196686515, 32528.89736696175, 31710.675998234063, 30915.612090503448, 30143.70564376991, 29394.956658033447, 28669.365133294057, 27966.931069551745, 27287.654466806507, 26631.535325058343, 25998.57364430726, 25388.769424553248, 24802.122665796313, 24238.633368036448, 23698.301531273664, 23181.127155507955, 22687.11024073932, 22216.25078696776, 21768.548794193277, 21344.004262415867, 20942.617191635538, 20564.38758185228, 20209.315433066095, 19877.400745276987, 19568.643518484954, 19283.043752690002, 19020.60144789212, 18781.316604091313, 18565.189221287583, 18372.21929948093, 18202.406838671348, 18055.751838858847, 17932.254300043416, 17831.914222225067, 17754.731605403787, 17700.706449579586, 17669.838754752458, 17662.128520922408, 17677.575748089428, 17716.18043625353, 17777.942585414705, 17862.862195572954, 17970.93926672828, 18102.173798880678, 18256.565792030153, 18434.115246176705, 18634.822161320335, 18858.686537461035, 19105.708374598813], \"type\": \"scatter\", \"uid\": \"c8bf03cc-0a4a-497d-9d77-f9029c201fa2\"}], {\"hovermode\": \"closest\", \"showlegend\": false, \"xaxis\": {\"showticklabels\": true, \"ticks\": \"\", \"zeroline\": false}, \"yaxis\": {\"showticklabels\": true, \"ticks\": \"\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"28155046-3ea1-4022-8cdd-767475bad2b2\")) {window._Plotly.Plots.resize(document.getElementById(\"28155046-3ea1-4022-8cdd-767475bad2b2\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"28155046-3ea1-4022-8cdd-767475bad2b2\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"28155046-3ea1-4022-8cdd-767475bad2b2\")) {\n",
       "    Plotly.newPlot(\"28155046-3ea1-4022-8cdd-767475bad2b2\", [{\"marker\": {\"color\": \"black\"}, \"mode\": \"markers\", \"name\": \"Training point\", \"x\": [10000, 400000, 5000, 0, 1000, 100000, 50000, 50, 20000, 200000], \"y\": [31000, 19000, 32000, 40000, 33000, 26000, 29000, 35000, 30000, 20000], \"type\": \"scatter\", \"uid\": \"175198de-73de-45f3-8b61-26b1eddf4b27\"}, {\"line\": {\"color\": \"green\", \"width\": 3}, \"mode\": \"lines\", \"name\": \"Regression line\", \"x\": [10000, 400000, 5000, 0, 1000, 100000, 50000, 50, 20000, 200000], \"y\": [32418.47367118483, 15827.777194804326, 32631.174908061505, 32843.87614493818, 32801.33589756284, 28589.851407404716, 30716.863776171445, 32841.74913256941, 31993.071197431487, 24335.826669871254], \"type\": \"scatter\", \"uid\": \"9fba6c24-6a5c-4bbe-b72f-c84cf5d449e5\"}, {\"line\": {\"color\": \"blue\", \"width\": 3}, \"mode\": \"lines\", \"name\": \"Regression curve\", \"x\": [0.0, 8163.265306122449, 16326.530612244898, 24489.79591836735, 32653.061224489797, 40816.32653061225, 48979.5918367347, 57142.857142857145, 65306.12244897959, 73469.38775510204, 81632.6530612245, 89795.91836734694, 97959.1836734694, 106122.44897959183, 114285.71428571429, 122448.97959183673, 130612.24489795919, 138775.51020408163, 146938.77551020408, 155102.04081632654, 163265.306122449, 171428.57142857142, 179591.83673469388, 187755.10204081633, 195918.3673469388, 204081.63265306124, 212244.89795918367, 220408.16326530612, 228571.42857142858, 236734.69387755104, 244897.95918367346, 253061.22448979592, 261224.48979591837, 269387.7551020408, 277551.02040816325, 285714.28571428574, 293877.55102040817, 302040.8163265306, 310204.0816326531, 318367.3469387755, 326530.612244898, 334693.8775510204, 342857.14285714284, 351020.4081632653, 359183.67346938775, 367346.93877551024, 375510.20408163266, 383673.4693877551, 391836.7346938776, 400000.0], \"y\": [34234.81248740836, 33370.276196686515, 32528.89736696175, 31710.675998234063, 30915.612090503448, 30143.70564376991, 29394.956658033447, 28669.365133294057, 27966.931069551745, 27287.654466806507, 26631.535325058343, 25998.57364430726, 25388.769424553248, 24802.122665796313, 24238.633368036448, 23698.301531273664, 23181.127155507955, 22687.11024073932, 22216.25078696776, 21768.548794193277, 21344.004262415867, 20942.617191635538, 20564.38758185228, 20209.315433066095, 19877.400745276987, 19568.643518484954, 19283.043752690002, 19020.60144789212, 18781.316604091313, 18565.189221287583, 18372.21929948093, 18202.406838671348, 18055.751838858847, 17932.254300043416, 17831.914222225067, 17754.731605403787, 17700.706449579586, 17669.838754752458, 17662.128520922408, 17677.575748089428, 17716.18043625353, 17777.942585414705, 17862.862195572954, 17970.93926672828, 18102.173798880678, 18256.565792030153, 18434.115246176705, 18634.822161320335, 18858.686537461035, 19105.708374598813], \"type\": \"scatter\", \"uid\": \"c8bf03cc-0a4a-497d-9d77-f9029c201fa2\"}], {\"hovermode\": \"closest\", \"showlegend\": false, \"xaxis\": {\"showticklabels\": true, \"ticks\": \"\", \"zeroline\": false}, \"yaxis\": {\"showticklabels\": true, \"ticks\": \"\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"28155046-3ea1-4022-8cdd-767475bad2b2\")) {window._Plotly.Plots.resize(document.getElementById(\"28155046-3ea1-4022-8cdd-767475bad2b2\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polynomial = np.poly1d([m_2, m_1, m_0])\n",
    "\n",
    "x_new = np.linspace(min(car_mileages), max(car_mileages), 50)\n",
    "y_new = polynomial(x_new)\n",
    "\n",
    "regression_curve = go.Scatter(\n",
    "    x=x_new,\n",
    "    y=y_new,\n",
    "    mode='lines',\n",
    "    line=dict(color='blue', width=3),\n",
    "    name='Regression curve')\n",
    "\n",
    "figure = go.Figure(data=[plot_data,\n",
    "                         calculus_linear_regression_line,\n",
    "                         regression_curve],\n",
    "                   layout=layout)\n",
    "\n",
    "ply.iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidjevši plavu krivu, nam je još jasnije zašto je novodobiveni MSE toliko niže vrijednosti od prethodnog. Naime, plava kriva, kojoj odgovara novi MSE, je uglavnom \"bliža\" našim trening tačkama od linearne, zelene, prave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kriva $p_2$ se još naziva i **regresionom krivom** stepena dva ili **kvadratnom regresionom krivom**, a cijeli koncept kroz koji smo pronašli istu **regresijom drugog stepena** ili **kvadratnom regresijom**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nameće se pitanje, da li možemo dodatno smanjiti MSE ukoliko još dodatno povećamo stepen regresione krive. Šta mislite? Saznati ćemo u narednim vježbama!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
