{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statističko učenje\n",
    "\n",
    "**Motivacija**: Trebamo da razumijemo zadatke regresije i klasifikacije, te kako možemo postići rezultate i šta nas treba interesovati kada budemo primijenjivali buduće algoritme u rješavanju problema analize podataka i prediktivne analize.\n",
    "\n",
    "**Cilj**: Razumijeti sljedeće koncepte:\n",
    "\n",
    "- Tipove varijable, te kako utiču na način rješavanja problema\n",
    "- Razliku između predikcije i zaključka (*inference*)\n",
    "- Procjenu funkcije $f$\n",
    "- Koncept tačnosti (*accuracy*) modela i na čemu treba da se obrati pažnja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uvod\n",
    "\n",
    "Unosi (*inputs, features, independent variables*) - označavamo sa $X$\n",
    "\n",
    "Izlazi (*outputs, response, dependent variables*) - označavamo sa $Y$\n",
    "\n",
    "Pretpostavimo da imamo kvantitativni odgovor $Y$ i $p$ različitih osobina $X_1, X_2, \\dots, X_p$. Pretpostavljamo da postoji neka veza između $Y$ i $X = (X_1, X_2, \\dots, X_p)$, koja se može iskazati u veoma generalnoj formi\n",
    "\n",
    "$$Y = f(X) + \\epsilon$$\n",
    "\n",
    "gdje je $f$ neka fiksna ali nepoznata funkcija od $X_1, X_2, \\dots, X_p$ i $\\epsilon$ je slučajni *član greške* nezavisna od $X$ i ima sredinu (misli se na *mean* ili aritmetička sredina) 0. $f$ predstavlja sistematsku informaciju koja $X$ daje za $Y$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funckija $f$\n",
    "\n",
    "Razlozi za pronalaženje funkcije $f$:\n",
    "- Predikcija\n",
    "- Zaključak\n",
    "\n",
    "#### Predikcija\n",
    "\n",
    "Možemo predvidjeti $Y$ koristeći\n",
    "\n",
    "$$ \\hat{Y} = \\hat{f}(X) $$\n",
    "\n",
    "gdje $\\hat{f}$ predstavlja našu procjenu za $f$ (*black box*), a $\\hat{Y}$ predstavlja rezultat predikcije za $Y$. \n",
    "\n",
    "Tačnost predikcije $\\hat{Y}$ zavisi od dvije vrste kvantiteta: svodljive greške i nesvodljive greške\n",
    "\n",
    "Pretpostavimo da procjena $\\hat{f}$ i skup osobina $X$, koji daju sljedeću predikciju $\\hat{Y} = \\hat{f}(X)$. Neka su u ovom trenutku i $\\hat{f}$ i $X$ fiksirani. Pokaže se da:\n",
    "\n",
    "$$ E(Y - \\hat{Y})^2 = [f(X) - \\hat{f}(X)]^2 + \\text{Var}(\\epsilon)$$\n",
    "\n",
    "gdje $E(Y - \\hat{Y})^2$ predstavlja sredinu ili *očekivanu vrijednost* od kvadratne razlike između predviđene i prave vrijednosti $Y$, a $\\text{Var}(\\epsilon)$ predstavlja varijansu asocirana sa članom greške $\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funckija $f$\n",
    "\n",
    "#### Zaključak\n",
    "\n",
    "- Koje osobine su povezani sa izlazom, to jeste, odgovorom?\n",
    "- Koji je odnos između odgovora i svake osobine?\n",
    "- Da li odnos između $Y$ i svake osobine može adekvatno sumirati koristeći linearnu jednačinu, ili je odnos komplikovaniji?\n",
    "\n",
    "Primjer: Razlika u rješavanju problema oko cijene kuća\n",
    "\n",
    "- Za predikciju: Da li je kuća jeftina ili skupa?\n",
    "- Za zaključak: Kako će se cijena promijeniti ukoliko ima pogled na more?\n",
    "\n",
    "*Razmjena*: Da li želimo imati jednostavan model (npr. linearan model) koji možemo jednostavno interpretirati za cijenu tačnosti modela ili želimo vrlo komplikovane nelinearne koji potencijalno mogu dati visoku tačnost pod cijenu teže interpretacije modela gdje je teže dobiti zaključke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Procjena funkcije $f$\n",
    "\n",
    "Pretpostavka je da imamo posmatrani skup $n$ različitih tačaka podataka, koje nazivamo *trening* skupom i pretpostavimo da jedan takav posmatrani podatak  ima $p$ osobina. Neka $x_{ij}$ predstavlja vrijednost {j}-tu osobinu ili ulaz za posmatranu $i$-tu tačku, gdje $i = 1, 2, \\dots, n$ i $j = 1, 2, \\dots, p$. Odgovarajuće, neka $y_i$ predstavlja varijablu odgovora ili izlaz za $i$-tu posmatranu tačku. Onda naš trening skup se sastoji od $\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}$, gdje $x_i = (x_{i1}, x_{i2}, \\dots, x_{ip})^T$.\n",
    "\n",
    "**Cilj**: Primijeniti metod statističkog učenja na trening podatke u svrhu procjene nepoznate funkcije $f$. Drugim riječima, želimo naći funkciju $\\hat{f}$ tako da $Y \\approx \\hat{f}(X)$ za bilo koju posmatranu tačku $(X, Y)$. Većina metoda statističkog učenja mogu se karakterizirati kao parametrične ili neparametrične."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Procjena funkcije $f$\n",
    "\n",
    "#### Parametarske metode\n",
    "\n",
    "1. Pretpostavka o funkcionalnoj formi ili obliku $f$. Naprimjer, vrlo jednostavna pretpostavka je da je $f$ linearna od $X$ (linearni model):\n",
    "\n",
    "$$ f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p $$\n",
    "\n",
    "2. Nakon selekcije modela, odabrati proceduru koja koristi trening podatke kako bi *trenirali* model ili napravili model da odgovara (*fit*) skupu podataka. To jeste, za linearan model želimo procjeniti parametre $\\beta_0, \\beta_1, \\dots, \\beta_p$ tako da:\n",
    "\n",
    "$$ Y \\approx \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p$$\n",
    "\n",
    "Ovo je *model-based* pristup i odnosi se kao parametarski; umanjuje problem procjene $f$ na procjenu skup parametara. Mana ovog pristupa jeste što često nećemo nećemo naći pravu nepoznatu formu $f$.  Možemo probati riješiti problem odabirom *fleksibilnih* modela koji mogu odgovarati mnogo mogućih funkcionalnih formi za $f$, s tim da zahtijeva procjenu mnogo veći broj parametara. Također postoji rizik i *overfitting* podataka. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Procjena funkcije $f$\n",
    "\n",
    "#### Neparametarske metode\n",
    "\n",
    "Ne pretpostavlja se eksplicitno forma o funkcionalnoj formi $f$, nego se traži procjena $f$ koja ide tačakama podataka što bliže moguće bez da bude previše grub ili valovit.\n",
    "\n",
    "Za razliku od parametarskih metoda, imaju potencijal da precizno odgovaraju širok spektar mogućih oblika procjene $f$. Svaka parametarska metoda ima vjerovatnoću da funkcionalna forma korištena za procjenu $f$ je mnogo različita od prave forme $f$, gdje u tom slučaju model neće dobro odgovarati podacima. Nedostatak je što se ne umanjuje problem procjene $f$ na relativno mal broj parametara, pa zbog toga je potrebno veliki broj posmatranja u svrhu pronalaska tačne procjene za $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regresioni i klasifikacijski problemi\n",
    "\n",
    "Vrste varijabli:\n",
    "\n",
    "- Kvantitativni\n",
    "- Kvalitativni (diskretni ili kategorični)\n",
    "\n",
    "Problemi sa kvantitativnim odgovorom - **regresija**, a problemi sa kvalitativnim odgovorom - **klasifikacija**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tačnost modela\n",
    "\n",
    "*No free lunch teorem* - nijedan model ne dominira druge modele nad svim mogućim skupovima podataka.\n",
    "\n",
    "### Mjerenje kvaliteta odgovora (*fit*)\n",
    "\n",
    "Kako bismo evaluirali metod statističkog učenja nad datim skupom podataka, moramo imati neku mjeru koliko dobro njegove predikcije se zapravo poklapaju sa posmatranim podacima. U regresiji, najčešće korištena mjera je *mean squared error* (MSE)\n",
    "\n",
    "$$ \\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{f}(x_i))^2 $$\n",
    "\n",
    "gdje je $\\hat{f}(x_i)$ je predikcija koja $\\hat{f}$ daje za $i$-tu posmatranu tačku (može se reći i posmatranje). Ovaj MSE se računa na osnovu trening skupom podataka, pa tačnije ga je nazvati trening MSE. Nas najviše treba da interesuje tačnost predikcija koje dobijemo kada primijenimo našu metodu na prethodno neviđenim testnim podacima.\n",
    "\n",
    "Pretpostavimo da smo *fit*-ovali našu metodu statističkog učenja na naše trening posmatranja $\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}$ i dobili smo našu procjenu $\\hat{f}$. Neka imamo $(x_0, y_0)$ koja predstavlja prethodno neviđeno testno posmatranje koja nije iskorištena u treningu metode statističkog učenja. Želimo odabrati metodu koja daje najmanju testni MSE, ne nužno i najmanji trening MSE. Drugim riječima, ako bismo imali velik broj testnih posmatranja, možemo izračunati\n",
    "\n",
    "$$ \\text{Ave}(y_0 - \\hat{f}(x_0))^2 $$\n",
    "\n",
    "prosječna kvadratna greška za ova testna posmatranja $(x_0, y_0)$. Želimo odabrati model čiji prosjek ovog kvantiteta - testni MSE - je što manja moguća."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pristranost-varijansa razmjena\n",
    "\n",
    "Testni MSE se može uvijek biti rastavljena na tri fundamentalna kvantiteta: *varijansa* $\\hat{f}(x_0)$, *kvadrat pristranosti* $\\hat{f}(x_0)$ i *varijansa* člana greške $\\epsilon$.\n",
    "\n",
    "$$ E\\big(y_0 - \\hat{f}(x_0)\\big)^2 = \\text{Var}(\\hat{f}(x_0)) + [\\text{Bias}(\\hat{f}(x_0))]^2 + \\text{Var}(\\epsilon) $$\n",
    "\n",
    "Ovdje $E\\big(y_0 - \\hat{f}(x_0)\\big)^2$ definira očekivani testni MSE i odnosi se na prosječni testni MSE koju bismo dobili ukoliko bismo ponavljajući procjenjivali $f$ koristeći veliki broj skupa podataka i svaki testirali nad $x_0$.\n",
    "\n",
    "Varijansa označava količinu koliko $\\hat{f}$ bi se promijenila ukoliko bismo je procijenili koristeći drugi drugi trening skup podataka. Općenito, fleksibilni modeli imaju visoku varijansu.\n",
    "\n",
    "Pristranost, u drugu ruku, odnosi se na grešku koja je uvedena od strane aproksimiranja problema stvarnog života, koji može biti izuzetno komplikovan. Općenito fleksibilni modeli imaju malu pristranost.\n",
    "\n",
    "Brzina promjene pristranosti i varijanse odlučuju da li testni MSE smanjuje ili raste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Postavka klasifikacije\n",
    "\n",
    "Pretpostavka je da se tražimo procjenu $f$ na osnovu trening posmatranja $\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}$, gdje su sada $y_1, y_2, \\dots, y_n$ kvalitativni. Najčešći pristup za mjerenje tačnosti procjene $\\hat{f}$ je trening *error rate*, proporcije grešaka koja se napravi ukoliko primijenimo našu procjenu $\\hat{f}$ na trening posmatranja:\n",
    "\n",
    "$$ \\frac{1}{n}\\sum_{i=1}^nI(y_i \\neq \\hat{y}_i) $$\n",
    "\n",
    "Ovdje je $\\hat{y}_i$ predviđena oznaka klase za $i$-to posmatranje koristeći se procjene $\\hat{f}$, a $I(y_i \\neq \\hat{y}_i)$ je varijabla indikatora koja je jednaka 1 ukoliko je $y_i \\neq \\hat{y}_i$ ili 0, u suprotnom. \n",
    "\n",
    "Testni *error rate* sa skupom testnih posmatranja u obliku $(x_0, y_0)$ je\n",
    "\n",
    "$$ Ave(I(y_0 \\neq \\hat{y}_0)) $$\n",
    "\n",
    "gdje je $\\hat{y_0}$ je predviđena oznaka klase koji je rezultat primjene klasifikatora na testno posmatranje sa prediktorom $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "- James, G., Witten, D., Hastie, T. and Tibshirani, R. (2013). *An Introduction to Statistical Learning with Applications in R*. Springer Science+Business Media, New York, NY, USA"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
