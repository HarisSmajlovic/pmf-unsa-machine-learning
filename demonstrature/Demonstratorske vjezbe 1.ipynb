{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statističko učenje\n",
    "\n",
    "**Motivacija**: Trebamo da razumijemo zadatke regresije i klasifikacije, te kako možemo postići rezultate i šta nas treba interesovati kada budemo primijenjivali buduće algoritme u rješavanju problema analize podataka i prediktivne analize.\n",
    "\n",
    "**Cilj**: Razumijeti sljedeće koncepte:\n",
    "\n",
    "- Tipove varijable, te kako utiču na način rješavanja problema\n",
    "- Razliku između predikcije i zaključka (*inference*)\n",
    "- Procjenu funkcije $f$\n",
    "- Koncept tačnosti (*accuracy*) modela i na čemu treba da se obrati pažnja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uvod\n",
    "\n",
    "Unosi (*inputs, features, independent variables*) - označavamo sa $X$\n",
    "\n",
    "Izlazi (*outputs, response, dependent variables*) - označavamo sa $Y$\n",
    "\n",
    "Pretpostavimo da imamo kvantitativni odgovor $Y$ i $p$ različitih osobina $X_1, X_2, \\dots, X_p$. Pretpostavljamo da postoji neka veza između $Y$ i $X = (X_1, X_2, \\dots, X_p)$, koja se može iskazati u veoma generalnoj formi\n",
    "\n",
    "$$Y = f(X) + \\epsilon$$\n",
    "\n",
    "gdje je $f$ neka fiksna ali nepoznata funkcija od $X_1, X_2, \\dots, X_p$ i $\\epsilon$ je slučajni *član greške* nezavisna od $X$ i ima sredinu 0 (misli se na *mean*/aritmetičku sredinu). Funkcija $f$ predstavlja sistematsku informaciju gdje $X$ daje za $Y$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funckija $f$\n",
    "\n",
    "Razlozi za pronalaženje funkcije $f$:\n",
    "- Predikcija\n",
    "- Zaključak\n",
    "\n",
    "#### Predikcija\n",
    "\n",
    "Možemo predvidjeti $Y$ koristeći\n",
    "\n",
    "$$ \\hat{Y} = \\hat{f}(X) $$\n",
    "\n",
    "gdje $\\hat{f}$ predstavlja našu procjenu za $f$ (u svrhu predikcije je *black box*), a $\\hat{Y}$ predstavlja rezultat predikcije za $Y$. \n",
    "\n",
    "Tačnost predikcije $\\hat{Y}$ zavisi od dvije vrste kvantiteta: *svodljive* greške i *nesvodljive* greške"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funckija $f$\n",
    "\n",
    "\n",
    "Pretpostavimo da imamo procjenu $\\hat{f}$ i skup osobina $X$, koji daju sljedeću predikciju $\\hat{Y} = \\hat{f}(X)$. Neka su u ovom trenutku i $\\hat{f}$ i $X$ fiksirani. Pokaže se da:\n",
    "\n",
    "$$ E(Y - \\hat{Y})^2 = [f(X) - \\hat{f}(X)]^2 + \\text{Var}(\\epsilon)$$\n",
    "\n",
    "gdje $E(Y - \\hat{Y})^2$ predstavlja prosječnu ili *očekivanu vrijednost* od kvadratne razlike između predviđene i prave vrijednosti $Y$, a $\\text{Var}(\\epsilon)$ predstavlja varijansu asocirana sa članom greške $\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funckija $f$\n",
    "\n",
    "#### Zaključak\n",
    "\n",
    "- Koje osobine su povezani sa izlazom, to jeste, odgovorom?\n",
    "- Koji je odnos između odgovora i svake osobine?\n",
    "- Da li odnos između $Y$ i svake osobine možemo adekvatno sumirati koristeći linearnu jednačinu, ili je taj odnos komplikovaniji?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funkcija $f$\n",
    "\n",
    "**Primjer**: Razlika u rješavanju problema oko cijene kuća\n",
    "\n",
    "- Za predikciju: Da li je kuća jeftina ili skupa?\n",
    "- Za zaključak: Kako će se cijena kuće promijeniti ukoliko ima pogled na more?\n",
    "\n",
    "Postoji razmjena (*trade-off*). Da li želimo imati: \n",
    "- Jednostavan model (*npr. linearan model*) koji možemo jednostavno interpretirati za cijenu tačnosti modela \n",
    "- Vrlo komplikovani nelinearni model koji potencijalno može dati visoku tačnost predikcije za cijenu teže interpretacije nađenog modela gdje teže možemo izvući zaključke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Procjena funkcije $f$\n",
    "\n",
    "Pretpostavimo da imamo posmatrani skup $n$ različitih tačaka podataka i pretpostavimo da svaka tačka podataka iz pomenutog skupa ima $p$ osobina. Neka $x_{ij}$ predstavlja vrijednost $j$-tu osobinu za posmatranu $i$-tu tačku podataka, gdje $i = 1, 2, \\dots, n$ i $j = 1, 2, \\dots, p$. Neka $y_i$ predstavlja varijablu odgovora ili izlaz za $i$-tu posmatranu tačku. Onda naš *trening skup* se sastoji od $\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}$, gdje $x_i = (x_{i1}, x_{i2}, \\dots, x_{ip})^T$ za $i = 1, 2, \\dots, n$.\n",
    "\n",
    "**Cilj**: Primijeniti metod statističkog učenja na trening podatke u svrhu procjene nepoznate funkcije $f$. Drugim riječima, želimo naći funkciju $\\hat{f}$ tako da $Y \\approx \\hat{f}(X)$ za bilo koju posmatranu tačku $(X, Y)$. \n",
    "\n",
    "Većina metoda statističkog učenja mogu se karakterizirati kao parametrične ili neparametrične."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Procjena funkcije $f$\n",
    "\n",
    "#### Parametarske metode\n",
    "\n",
    "1. Pretpostavka o funkcionalnoj formi ili obliku $f$. Naprimjer, jednostavno pretpostavimo da je $f$ linearne forme i prima $X$ kao unos (linearni model). Onda tražimo $f$ u sljedećem obliku:\n",
    "\n",
    "$$ f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p $$\n",
    "\n",
    "2. Nakon selekcije modela, treba odabrati proceduru koja koristi trening podatke kako bismo *trenirali* model ili napravili model da *fit*-uje skup podataka. Drugim riječima, za linearan model želimo procjeniti parametre $\\beta_0, \\beta_1, \\dots, \\beta_p$ tako da:\n",
    "\n",
    "$$ Y \\approx \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Procjena funckije $f$\n",
    "\n",
    "\n",
    "Ovo je *model-based* pristup i odnosi se kao parametarski. Prednost je da umanjuje problem procjene $f$ na procjenu skup parametara.\n",
    "\n",
    "Mana ovog pristupa jeste što često nećemo nećemo naći pravu nepoznatu formu $f$.  Možemo probati riješiti problem odabirom *fleksibilnih* modela koji mogu odgovarati mnogo mogućih funkcionalnih formi za $f$, s tim da zahtijeva procjenu mnogo veći broj parametara. Postoji rizik *overfitting* podataka za odabir *fleksibilnih* modela. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Procjena funkcije $f$\n",
    "\n",
    "#### Neparametarske metode\n",
    "\n",
    "Ne pretpostavlja se eksplicitno funkcionalna forma $f$, nego se traži procjena $f$ koja *fit*-uje što je bliže moguće tačakama podataka bez da funkcija $f$ bude previše gruba ili valovita.\n",
    "\n",
    "Za razliku od parametarskih metoda, neparametarske metode imaju potencijal da precizno odgovaraju podacima koristeći širok spektar mogućih oblika procjene $f$. Svaka parametarska metoda ima vjerovatnoću da funkcionalna forma korištena za procjenu $f$ je mnogo različita od prave forme $f$, gdje u tom slučaju model neće dobro odgovarati podacima. \n",
    "\n",
    "Nedostatak je što se ne umanjuje problem procjene $f$ na relativno mal broj parametara, pa zbog toga je potrebno veliki broj posmatranja u svrhu pronalaska tačne procjene za $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regresioni i klasifikacijski problemi\n",
    "\n",
    "Vrste varijabli:\n",
    "\n",
    "- Kvantitativni\n",
    "- Kvalitativni (diskretni ili kategorični)\n",
    "\n",
    "Problemi sa kvantitativnim odgovorom - **regresija**\n",
    "\n",
    "Problemi sa kvalitativnim odgovorom - **klasifikacija**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tačnost modela\n",
    "\n",
    "*No free lunch teorem* - nijedan model ne dominira druge modele nad svim mogućim skupovima podataka.\n",
    "\n",
    "### Mjerenje kvaliteta odgovora (*fit*)\n",
    "\n",
    "Kako bismo evaluirali metod statističkog učenja nad datim skupom podataka, moramo imati neku mjeru (*metrika*) koliko dobro njegove predikcije se zapravo poklapaju sa posmatranim podacima. U regresiji, najčešće korištena mjera je *mean squared error* (MSE)\n",
    "\n",
    "$$ \\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{f}(x_i))^2 $$\n",
    "\n",
    "gdje $\\hat{f}(x_i)$ je predikcija koja $\\hat{f}$ daje za $i$-tu posmatranu tačku (može se reći i posmatranje). Ovaj MSE se računa nad trening skupom podataka, pa tačnije ga je nazvati *trening MSE*. \n",
    "\n",
    "Nas najviše treba da interesuje tačnost predikcija koje dobijemo kada primijenimo našu metodu na prethodno neviđenim *testnim podacima*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mjerenje kvaliteta odgovora (*fit*)\n",
    "\n",
    "\n",
    "Pretpostavimo da smo *fit*-ovali našu metodu statističkog učenja nad trening posmatranjima $\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}$ i da smo dobili našu procjenu $\\hat{f}$. Neka imamo $(x_0, y_0)$ koja predstavlja prethodno neviđeno testno posmatranje koja nije iskorištena u treningu metode statističkog učenja. Želimo odabrati metodu koja daje najmanju testnu MSE, ne nužno i najmanju trening MSE. Drugim riječima, ako bismo imali velik broj testnih posmatranja, možemo izračunati\n",
    "\n",
    "$$ \\text{Ave}(y_0 - \\hat{f}(x_0))^2 $$\n",
    "\n",
    "što označava prosječnu kvadratnu grešku za ova testna posmatranja $(x_0, y_0)$. Želimo odabrati model čiji prosjek ovog kvantiteta (*testni MSE*) je što manja moguća."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pristranost-varijansa razmjena\n",
    "\n",
    "Testni MSE se može uvijek rastaviti na tri fundamentalna kvantiteta: *varijansa* $\\hat{f}(x_0)$, *kvadrat pristranosti (bias)* $\\hat{f}(x_0)$ i *varijansa* člana greške $\\epsilon$.\n",
    "\n",
    "$$ E\\big(y_0 - \\hat{f}(x_0)\\big)^2 = \\text{Var}(\\hat{f}(x_0)) + [\\text{Bias}(\\hat{f}(x_0))]^2 + \\text{Var}(\\epsilon) $$\n",
    "\n",
    "Ovdje $E\\big(y_0 - \\hat{f}(x_0)\\big)^2$ definira očekivani testni MSE i odnosi se na prosječni testni MSE koju bismo dobili ukoliko bismo ponavljajući procjenjivali $f$ nad velikim brojem tačaka podataka iz skupa podataka i svaku procjenu testirali nad $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pristranost-varijansa razmjena\n",
    "\n",
    "*Varijansa* označava količinu koliko $\\hat{f}$ bi se promijenila ukoliko bismo je procijenili koristeći drugi trening skup podataka. Općenito, fleksibilni modeli imaju visoku varijansu.\n",
    "\n",
    "*Pristranost (bias)*, u drugu ruku, odnosi se na grešku koja je uvedena od strane aproksimiranja problema iz stvarnog života, koji može biti izuzetno komplikovan. Općenito fleksibilni modeli imaju malu pristranost.\n",
    "\n",
    "Brzina promjene pristranosti i brzina promjene varijanse odlučuju da li testni MSE smanjuje ili raste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Postavka klasifikacije\n",
    "\n",
    "Pretpostavka je da tražimo procjenu $f$ na osnovu trening posmatranja $\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}$, gdje su sada $y_1, y_2, \\dots, y_n$ kvalitativni. Najčešći pristup za mjerenje tačnosti procjene $\\hat{f}$ je trening *error rate*, proporcije grešaka koja se napravi ukoliko primijenimo našu procjenu $\\hat{f}$ nad trening posmatranjima:\n",
    "\n",
    "$$ \\frac{1}{n}\\sum_{i=1}^nI(y_i \\neq \\hat{y}_i) $$\n",
    "\n",
    "Ovdje je $\\hat{y}_i$ predviđena oznaka klase za $i$-to posmatranje koristeći procjenu $\\hat{f}$, a $I(y_i \\neq \\hat{y}_i)$ je varijabla indikatora koja je jednaka 1 ukoliko je $y_i \\neq \\hat{y}_i$ ili 0, u suprotnom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Postavka klasifikacije\n",
    "\n",
    "Testni *error rate* sa skupom testnih posmatranja u obliku $(x_0, y_0)$ je\n",
    "\n",
    "$$ Ave(I(y_0 \\neq \\hat{y}_0)) $$\n",
    "\n",
    "gdje $\\hat{y_0}$ je predviđena oznaka klase koji je rezultat primjene klasifikatora nad testnim posmatranjima sa njihovim prediktorom (*osobinama*) $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reference\n",
    "\n",
    "- James, G., Witten, D., Hastie, T. and Tibshirani, R. (2013). *An Introduction to Statistical Learning with Applications in R*. Springer Science+Business Media, New York, NY, USA"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
