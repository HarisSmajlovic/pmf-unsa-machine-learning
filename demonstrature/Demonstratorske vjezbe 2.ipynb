{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linearna regresija\n",
    "\n",
    "**Motivacija**:\n",
    "\n",
    "**Cilj**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jednostavna linearna regresija\n",
    "\n",
    "Jednostavni pristup nadgledanog učenja, koristan za predviđanje kvantitativnog odgovora $Y$ na osnovnu jednog prediktora $X$. Pretpostavlja se da imamo aproksimativno linearni odnos između $X$ i $Y$. Ovaj odnos možemo napisati kao:\n",
    "\n",
    "$$ Y \\approx \\beta_0 + \\beta_1X $$\n",
    "\n",
    "gdje $\\beta_0$ i $\\beta_1$ su dvije nepoznate konstante koje predstavljaju odječak i i nagib pravca u linearnom modelu. Zajedno, $\\beta_0$ i $\\beta_1$ se zovu još i koeficijenti ili parametri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jednostavna linearna regresija\n",
    "\n",
    "Nakon što smo iskoristili trening skup da procijenimo $\\hat{\\beta}_0$ i $\\hat{\\beta}_1$ za koeficijente modela, možemo predvidjeti buduće kvantitativne odgovore računajući\n",
    "\n",
    "$$ \\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1x $$\n",
    "\n",
    "gdje $\\hat{y}$ pokazuje predikciju $Y$ na osnovu $X = x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procjenjivanje koeficijenata\n",
    "\n",
    "Neka nam je dat skup\n",
    "\n",
    "$$ (x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n) $$\n",
    "\n",
    "koji predstavljaju $n$ parova posmatranja, gdje svaki posjeduju mjeru $X$ i mjeru $Y$. Naš cilj je dobiti koeficijente $\\hat{\\beta}_0$ i $\\hat{\\beta}_1$ tako da linearni model *fit*-a dostupne podatke dobro, to jeste, tako da $y_i \\approx \\hat{\\beta}_0 + \\hat{\\beta}_1x_i$ za $i = 1, 2, \\dots, n$. Želimo da nađena linija je što bliže moguća ovim $n$ posmatranjima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procjenjivanje koeficijenata\n",
    "\n",
    "Najčešća mjera za blizinu modela jeste kriterij _najmanjih kvadrata_.\n",
    "\n",
    "Neka $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_i$ bude predikcija za $Y$ na osnovu $i$-te vrijednosti $X$. Onda $e_i = y_i - \\hat{y}_i$ predstavlja $i$-ti *rezidual* - razlika između $i$-te vrijednosti posmatranog odgovora i $i$-te vrijednosti predikcije odgovora od našeg modela. Definišemo RSS (*rezidualna suma kvadrata*)\n",
    "\n",
    "$$ \\text{RSS} = e_1^2 + e_2^2 + \\dots + e_n^2 $$\n",
    "\n",
    "ili, ekvivalentno\n",
    "\n",
    "$$ \\text{RSS} = (y_1 - \\hat{\\beta}_0 - \\hat{\\beta}_1x_1)^2 + (y_2 - \\hat{\\beta}_0 - \\hat{\\beta}_1x_2)^2 + \\dots + (y_n - \\hat{\\beta}_0 - \\hat{\\beta}_1x_n)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procjenjivanje koeficijenata\n",
    "\n",
    "Najmanji kvadrati koriste $\\hat{\\beta}_0$ i $\\hat{\\beta}_1$ kako bi minimizirali koeficijente. Iz RSS, parcijalnom derivacijom RSS po $\\hat{\\beta}_0$ ćemo dobiti minimajzer za $\\hat{\\beta}_0$, a za minimajzer za $\\hat{\\beta}_1$ slično uradimo parcijalno derivacijom po $\\hat{\\beta}_1$ dobijamo:\n",
    "\n",
    "$$ \\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} $$\n",
    "\n",
    "$$ \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x} $$\n",
    "\n",
    "gdje $\\bar{y} \\equiv \\frac{1}{n}\\sum_{i=1}^{n}y_i$ i $\\bar{x} \\equiv \\frac{1}{n}\\sum_{i=1}^{n}x_i$ su aritmetičke sredine uzoraka (*sample means*). Drugim riječima, ovi minimajzeri definišu *koeficijente procijenjenim najmanjim kvadratima* za jednostavnu linearnu regresiju. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procjenjivanje tačnosti procjena koeficijenata\n",
    "\n",
    "Sjetimo se da pretpostavljamo da *pravi* odnos između $X$ i $Y$ ima formu $Y = f(X) + \\epsilon$ za neku nepoznatu funkciju $f$, gdje $\\epsilon$ je nul-aritmetičke sredine slučajni član greške. Ukoliko $f$ će biti aproksimirana linearnom funkcijom, onda možemo napisati ovaj odnos kao:\n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1X + \\epsilon $$\n",
    "\n",
    "$\\beta_0$ predstavlja član odsječka, to jeste, očekivana vrijednost $Y$ kada je $X = 0$, a $\\beta_1$ predstavlja nagib, što znači prosječni rast $Y$ povezana sa rastom jedinice mjere u $X$, dok član greške obuhvata ostale tačke koje jednostavni model promaši. Pretpostavljamo da član greške ne zavisi od $X$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procjenjivanje tačnosti procjena koeficijenata\n",
    "\n",
    "$Y = \\beta_0 + \\beta_1X + \\epsilon$ predstavlja *populacijska regresiona linija*, što je najbolja linearna aproksimacija pravog odnosa između $X$ i $Y$. Regresioni koeficijenti najmanjih kvadrata karakteriziraju *liniju najmanjih kvadrata*. \n",
    "\n",
    "\n",
    "\n",
    "(Ovdje prikazati ilustraciju na sample data, prikazivajući rad prethodnih jednačina, 64. stranica)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
